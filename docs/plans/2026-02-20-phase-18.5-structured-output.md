# Phase 18.5: Structured LLM Output (JSON)

**Status:** Draft for Review
**Priority:** HIGH
**Dependencies:** Phase 18 (Tree + Evidence + Recursion) ✓

---

## Goal

Make `llm()` return structured JSON instead of raw text for **token efficiency** and **reliability**.

**Key outcomes:**
1. 20-50% token savings on complex responses
2. Reliable parsing (no fragile regex)
3. Structured reasoning (step-by-step)
4. Explicit recursion via `sub_tasks` field
5. Safe fallback when parsing fails

---

## Why This Matters

| Benefit | Impact |
|---------|--------|
| **Parseable output** | No more fragile string parsing |
| **Fewer tokens** | 20-50% savings on long responses |
| **Structured reasoning** | Forces cleaner agent thinking |
| **Error detection** | Missing keys → clear failure |
| **Future-proof** | Easy to add fields later |

**Real-world example:**
- Raw text response: ~800-1200 tokens
- JSON with structured fields: ~500-800 tokens
- → **30-40% savings**

---

## JSON Schema

Keep it minimal but powerful:

```json
{
  "reasoning": "Step-by-step thinking (optional but encouraged)",
  "conclusion": "Final answer or summary",
  "confidence": 0.85,
  "files": ["src/auth.py", "src/frame/causal_frame.py"],
  "sub_tasks": [
    {"query": "Analyze auth.py login flow", "priority": 1},
    {"query": "Check OAuth implementation", "priority": 2}
  ],
  "needs_more_info": false,
  "next_action": "finalize"
}
```

**Field descriptions:**

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `reasoning` | string | Optional | Step-by-step thinking |
| `conclusion` | string | Required | Final answer |
| `confidence` | float | Optional | 0.0-1.0, default 0.8 |
| `files` | array | Optional | Relevant file paths |
| `sub_tasks` | array | Optional | Explicit recursion hints |
| `needs_more_info` | bool | Optional | True if agent is stuck |
| `next_action` | string | Optional | `"continue"` \| `"finalize"` \| `"ask_user"` |
| `error` | string | Optional | If format failed |

**`next_action` values:**

| Value | Meaning |
|-------|---------|
| `"continue"` | More sub-tasks needed, keep recursing |
| `"finalize"` | Ready for final answer, stop recursion |
| `"ask_user"` | Need clarification, pause for user input |

This prevents infinite recursion when the agent is unsure.

---

## Implementation Tasks

### Task 1: Update System Prompt

**File:** `src/repl/rlaph_loop.py` — `_build_system_prompt()`

Add JSON format enforcement with hardened prompt:

```python
def _build_system_prompt(self) -> str:
    return f"""You are an RLM (Recursive Language Model) agent with access to a REAL Python REPL.

CRITICAL OUTPUT FORMAT:
You MUST respond in valid JSON only. No other text before or after.
The response must be raw JSON only, starting with {{ and ending with }}.
Do NOT wrap in ```json code blocks.

Use this exact schema:

{{
  "reasoning": "Your step-by-step thinking here",
  "conclusion": "Final answer or summary",
  "confidence": 0.0 to 1.0,
  "files": ["relevant/file.py", ...] or [],
  "sub_tasks": [{{"query": "sub query", "priority": 1}}] or [],
  "needs_more_info": true or false,
  "next_action": "continue" or "finalize" or "ask_user"
}}

"next_action": Must be one of:
- "continue" (more sub-tasks needed)
- "finalize" (ready for final answer)
- "ask_user" (need clarification)

If you cannot follow this format, output: {{"error": "invalid format", "conclusion": "your answer"}}

CRITICAL RULES:
1. When you write code in ```python blocks, the system EXECUTES it and returns REAL output
2. DO NOT generate fake "REPL output" or "Human:" messages yourself
3. DO NOT pretend to see execution results - wait for the actual system response
4. After writing code, STOP and wait for the [SYSTEM - Code execution result]
5. When you have the final answer, write: {{"conclusion": "<answer>", "confidence": 0.9}}

RECURSION - DECOMPOSE COMPLEX TASKS:
You can call llm(sub_query) to delegate sub-tasks. This creates a CHILD FRAME.
- Max recursion depth: {self.max_depth}
- Use llm(sub_query) for parallel/branching analysis
- Each llm() call is tracked as a child frame
- Example: For codebase summary, first glob files, then llm("summarize auth/*.py")

IMPORTANT RECURSION RULES:
- Only call llm(sub_query) when the sub-task is meaningfully independent or parallelizable
- Do NOT call llm() for tiny steps — that wastes depth budget
- Always prefer small, focused sub-queries (1–3 sentences)
- If you're unsure, try simple code first, then recurse if needed

MANDATORY: After all sub-tasks complete, you MUST synthesize and write:
{{"conclusion": "<complete answer combining all results>", "confidence": 0.9}}

Do NOT leave the answer incomplete. Do NOT end without the JSON conclusion.

Pre-loaded Libraries (NO import needed):
- hashlib: Use directly as `hashlib.sha256(data.encode()).hexdigest()`
- json: Use directly as `json.loads()`, `json.dumps()`
- re: Use directly for regex operations

File Access Functions:
- `read_file(path, offset=0, limit=2000)`: Read file content from disk
- `glob_files(pattern)`: Find files matching pattern
- `grep_files(pattern, path)`: Search for pattern in files
- `list_dir(path)`: List directory contents

Recursion Function:
- `llm(query)`: Call LLM with sub-query, returns JSON result string
  - Creates child frame at depth+1
  - Use for task decomposition
  - Keep sub-queries focused (1-3 sentences)
"""
```

### Task 2: Safe JSON Parser

**File:** `src/repl/json_parser.py` (NEW)

```python
"""Safe JSON parsing for LLM responses."""
import json
import logging
from dataclasses import dataclass, field
from typing import Any, Literal

logger = logging.getLogger(__name__)

# Type for next_action field
NextAction = Literal["continue", "finalize", "ask_user"]


@dataclass
class StructuredResponse:
    """Parsed LLM response with safe defaults."""
    reasoning: str = ""
    conclusion: str = ""
    confidence: float = 0.8
    files: list[str] = field(default_factory=list)
    sub_tasks: list[dict] = field(default_factory=list)
    needs_more_info: bool = False
    next_action: NextAction = "finalize"
    error: str | None = None
    raw_response: str = ""

    @property
    def is_valid(self) -> bool:
        """Check if response was parsed successfully."""
        return self.error is None and bool(self.conclusion)

    @property
    def should_continue(self) -> bool:
        """Check if agent wants to continue recursion."""
        return self.next_action == "continue" and bool(self.sub_tasks)

    @property
    def should_ask_user(self) -> bool:
        """Check if agent needs user input."""
        return self.next_action == "ask_user" or self.needs_more_info


def _clamp_confidence(value: Any) -> float:
    """Clamp confidence to valid range [0.0, 1.0]."""
    try:
        conf = float(value)
        return max(0.0, min(1.0, conf))
    except (TypeError, ValueError):
        return 0.8  # Default


def _parse_next_action(value: Any) -> NextAction:
    """Parse next_action with validation."""
    if value in ("continue", "finalize", "ask_user"):
        return value
    return "finalize"  # Safe default


def parse_llm_response(raw: str) -> StructuredResponse:
    """
    Parse LLM response into structured format with safe fallback.

    Args:
        raw: Raw LLM response string

    Returns:
        StructuredResponse with parsed fields or safe defaults
    """
    # Strip whitespace
    raw = raw.strip()

    # Try to extract JSON from potential markdown code blocks
    json_str = raw
    if raw.startswith("```json"):
        json_str = raw[7:].strip()  # Remove ```json
    elif raw.startswith("```"):
        json_str = raw[3:].strip()  # Remove ```

    if json_str.endswith("```"):
        json_str = json_str[:-3].strip()  # Remove closing ```

    # Try to parse JSON
    try:
        data = json.loads(json_str)

        response = StructuredResponse(
            reasoning=data.get("reasoning", ""),
            conclusion=data.get("conclusion", ""),
            confidence=_clamp_confidence(data.get("confidence", 0.8)),
            files=data.get("files", []),
            sub_tasks=data.get("sub_tasks", []),
            needs_more_info=data.get("needs_more_info", False),
            next_action=_parse_next_action(data.get("next_action", "finalize")),
            error=data.get("error"),
            raw_response=raw,
        )

        # Log token savings (rough estimate)
        raw_tokens = len(raw) // 4
        parsed_tokens = len(response.conclusion) // 4 + 100  # overhead
        if raw_tokens > parsed_tokens:
            logger.info(f"Token savings: raw={raw_tokens}, parsed={parsed_tokens}, saved={raw_tokens - parsed_tokens}")

        return response

    except json.JSONDecodeError as e:
        logger.warning(f"LLM did not return valid JSON: {e}")

        # Fallback: treat raw text as conclusion
        return StructuredResponse(
            conclusion=raw,
            confidence=0.5,  # Lower trust for unstructured response
            error="invalid_json",
            raw_response=raw,
        )

    except (TypeError, ValueError) as e:
        logger.warning(f"Error parsing LLM response: {e}")

        return StructuredResponse(
            conclusion=raw,
            confidence=0.5,
            error=str(e),
            raw_response=raw,
        )


def extract_conclusion(raw: str) -> str:
    """Quick helper to extract just the conclusion."""
    parsed = parse_llm_response(raw)
    return parsed.conclusion or raw


def extract_sub_tasks(raw: str) -> list[dict]:
    """Quick helper to extract sub_tasks for recursion."""
    parsed = parse_llm_response(raw)
    return parsed.sub_tasks
```

### Task 3: Update `llm_sync()` to Use Parser

**File:** `src/repl/rlaph_loop.py`

```python
from .json_parser import parse_llm_response, StructuredResponse

def llm_sync(self, query: str, context: str = "", depth: int | None = None) -> str:
    """
    Synchronous LLM call - returns actual result immediately.

    Now returns JSON string that can be parsed with parse_llm_response().
    """
    # ... existing depth calculation ...

    result = self.llm_client.call(
        query=query,
        context={"prior": context} if context else None,
        depth=current_depth,
    )

    # Parse response for structured data
    parsed = parse_llm_response(result)

    # Create child frame with parsed confidence
    # ... existing frame creation ...

    child_frame = CausalFrame(
        # ... existing fields ...
        conclusion=parsed.conclusion[:500] if parsed.conclusion else result[:500],
        confidence=parsed.confidence,  # Use parsed confidence
        # ... rest of fields ...
    )

    # Return raw result (caller can parse if needed)
    return result
```

### Task 4: Update Frame Creation in Main Loop

**File:** `src/repl/rlaph_loop.py`

```python
from .json_parser import parse_llm_response

# In the REPL_EXECUTE action handler:
elif item.action == ResponseAction.REPL_EXECUTE:
    # ... existing code execution ...

    # Parse the response for structured data
    parsed = parse_llm_response(response_content)

    frame = CausalFrame(
        # ... existing fields ...
        conclusion=parsed.conclusion[:500] if parsed.conclusion else str(exec_result.output)[:500],
        confidence=parsed.confidence,
        # ... rest of fields ...
    )
```

### Task 5: Handle `sub_tasks` for Explicit Recursion

**File:** `src/repl/rlaph_loop.py`

```python
from .json_parser import parse_llm_response

# After getting LLM response, check for sub_tasks:
parsed = parse_llm_response(response_content)

# Use next_action to control recursion
if parsed.should_continue and self._depth < self.max_depth:
    # Execute sub-tasks in order of priority
    sorted_tasks = sorted(parsed.sub_tasks, key=lambda t: t.get("priority", 999))

    for task in sorted_tasks:
        sub_query = task.get("query")
        if sub_query:
            if self._verbose:
                print(f"[RLM] Auto-recursing to sub-task: {sub_query[:60]}...")
            sub_result = self.llm_sync(sub_query, depth=current_depth + 1)
            # Sub-result is tracked as child frame automatically

elif parsed.should_ask_user:
    # Agent needs clarification - pause for user input
    if self._verbose:
        print(f"[RLM] Agent requesting user input: {parsed.reasoning[:100]}...")
    # Could inject a user prompt here or set a flag for the main loop

# next_action == "finalize" means no more recursion, proceed to final answer
```

### Task 6: Unit Tests for JSON Parser

**File:** `tests/repl/test_json_parser.py` (NEW)

```python
"""Tests for structured LLM response parsing."""
import pytest
from src.repl.json_parser import parse_llm_response, StructuredResponse


def test_parse_valid_json():
    """Should parse valid JSON response."""
    raw = '{"conclusion": "Test answer", "confidence": 0.9}'
    parsed = parse_llm_response(raw)

    assert parsed.is_valid
    assert parsed.conclusion == "Test answer"
    assert parsed.confidence == 0.9


def test_parse_with_all_fields():
    """Should parse all optional fields."""
    raw = '''{
        "reasoning": "Step 1, Step 2",
        "conclusion": "Final answer",
        "confidence": 0.85,
        "files": ["auth.py", "login.py"],
        "sub_tasks": [{"query": "Check auth", "priority": 1}],
        "needs_more_info": false,
        "next_action": "continue"
    }'''
    parsed = parse_llm_response(raw)

    assert parsed.reasoning == "Step 1, Step 2"
    assert parsed.conclusion == "Final answer"
    assert parsed.confidence == 0.85
    assert parsed.files == ["auth.py", "login.py"]
    assert len(parsed.sub_tasks) == 1
    assert parsed.needs_more_info is False
    assert parsed.next_action == "continue"
    assert parsed.should_continue is True


def test_parse_markdown_wrapped_json():
    """Should extract JSON from markdown code blocks."""
    raw = '''```json
{"conclusion": "Answer", "confidence": 0.8}
```'''
    parsed = parse_llm_response(raw)

    assert parsed.is_valid
    assert parsed.conclusion == "Answer"


def test_fallback_on_invalid_json():
    """Should fallback to raw text on invalid JSON."""
    raw = "This is not JSON, just plain text."
    parsed = parse_llm_response(raw)

    assert not parsed.is_valid
    assert parsed.conclusion == raw
    assert parsed.confidence == 0.5  # Lower trust
    assert parsed.error == "invalid_json"


def test_fallback_on_missing_conclusion():
    """Should handle missing conclusion field."""
    raw = '{"reasoning": "No conclusion here"}'
    parsed = parse_llm_response(raw)

    assert parsed.conclusion == ""
    assert parsed.is_valid is False  # No conclusion


def test_confidence_clamping_high():
    """Should clamp confidence > 1.0 to 1.0."""
    raw = '{"conclusion": "Test", "confidence": 1.5}'
    parsed = parse_llm_response(raw)

    assert parsed.confidence == 1.0


def test_confidence_clamping_low():
    """Should clamp confidence < 0.0 to 0.0."""
    raw = '{"conclusion": "Test", "confidence": -0.5}'
    parsed = parse_llm_response(raw)

    assert parsed.confidence == 0.0


def test_confidence_invalid_type():
    """Should use default for invalid confidence type."""
    raw = '{"conclusion": "Test", "confidence": "high"}'
    parsed = parse_llm_response(raw)

    assert parsed.confidence == 0.8  # Default


def test_next_action_validation():
    """Should validate next_action values."""
    # Valid values
    for action in ["continue", "finalize", "ask_user"]:
        raw = f'{{"conclusion": "Test", "next_action": "{action}"}}'
        parsed = parse_llm_response(raw)
        assert parsed.next_action == action

    # Invalid value defaults to finalize
    raw = '{"conclusion": "Test", "next_action": "invalid"}'
    parsed = parse_llm_response(raw)
    assert parsed.next_action == "finalize"


def test_should_continue_property():
    """Should determine if recursion should continue."""
    # Has sub_tasks and next_action=continue
    raw = '{"conclusion": "Test", "sub_tasks": [{"query": "x"}], "next_action": "continue"}'
    parsed = parse_llm_response(raw)
    assert parsed.should_continue is True

    # Has sub_tasks but next_action=finalize
    raw = '{"conclusion": "Test", "sub_tasks": [{"query": "x"}], "next_action": "finalize"}'
    parsed = parse_llm_response(raw)
    assert parsed.should_continue is False

    # next_action=continue but no sub_tasks
    raw = '{"conclusion": "Test", "sub_tasks": [], "next_action": "continue"}'
    parsed = parse_llm_response(raw)
    assert parsed.should_continue is False


def test_should_ask_user_property():
    """Should determine if user input is needed."""
    raw = '{"conclusion": "Test", "next_action": "ask_user"}'
    parsed = parse_llm_response(raw)
    assert parsed.should_ask_user is True

    raw = '{"conclusion": "Test", "needs_more_info": true}'
    parsed = parse_llm_response(raw)
    assert parsed.should_ask_user is True


def test_empty_response():
    """Should handle empty response."""
    raw = ""
    parsed = parse_llm_response(raw)

    assert parsed.conclusion == ""
    assert parsed.error == "invalid_json"
```

### Task 7: Integration Test

**File:** `tests/integration/test_structured_output.py` (NEW)

```python
"""Integration test for structured LLM output."""
import asyncio
import pytest
from pathlib import Path

from src.repl.rlaph_loop import RLAPHLoop
from src.repl.json_parser import parse_llm_response
from src.types import SessionContext


@pytest.mark.asyncio
async def test_llm_returns_structured_output():
    """LLM should return parseable JSON."""
    loop = RLAPHLoop(max_depth=2, verbose=True)
    context = SessionContext(files={}, messages=[])

    result = await loop.run(
        "What is 2+2? Return as JSON with conclusion and confidence.",
        context,
        working_dir=Path.cwd(),
        session_id="test_structured",
    )

    # Try to parse the answer as JSON
    parsed = parse_llm_response(result.answer)

    # Should have a conclusion (even if not perfect JSON)
    assert parsed.conclusion or result.answer


@pytest.mark.asyncio
async def test_sub_tasks_trigger_recursion():
    """sub_tasks field should trigger automatic recursion."""
    loop = RLAPHLoop(max_depth=3, verbose=True)
    context = SessionContext(files={}, messages=[])

    # This query should decompose into sub-tasks
    result = await loop.run(
        "Analyze src/frame/causal_frame.py and src/frame/frame_index.py. " +
        "Use sub_tasks to analyze each file separately.",
        context,
        working_dir=Path.cwd(),
        session_id="test_subtasks",
    )

    # Should have created child frames
    assert len(loop.frame_index) > 1

    # Check for depth > 0 frames (recursion happened)
    depths = [f.depth for f in loop.frame_index._frames.values()]
    assert max(depths) >= 1  # At least one recursive call


@pytest.mark.asyncio
async def test_next_action_controls_recursion():
    """next_action=finalize should prevent infinite recursion."""
    loop = RLAPHLoop(max_depth=5, verbose=True)
    context = SessionContext(files={}, messages=[])

    result = await loop.run(
        "Count from 1 to 3. Set next_action to 'finalize' when done.",
        context,
        working_dir=Path.cwd(),
        session_id="test_next_action",
    )

    # Should not exceed max depth
    assert result.depth_used < 5

    # Parse final response
    parsed = parse_llm_response(result.answer)
    assert parsed.next_action in ("finalize", None)  # Finalized or default
```

---

## File Changes Summary

| File | Change | Lines |
|------|--------|-------|
| `src/repl/rlaph_loop.py` | Update system prompt + use parser + next_action | +40 |
| `src/repl/json_parser.py` | NEW: Safe JSON parser with clamping + logging | +100 |
| `tests/repl/test_json_parser.py` | NEW: Parser unit tests (enhanced) | +80 |
| `tests/integration/test_structured_output.py` | NEW: Integration tests | +50 |

**Total:** ~270 lines of new/changed code

---

## Migration Path

### Phase 1: Add Parser (Non-Breaking)

1. Add `json_parser.py`
2. Update system prompt to request JSON
3. Use parser for frame creation, but keep raw response for return value

### Phase 2: Handle sub_tasks

1. Check for `sub_tasks` in parsed response
2. Auto-recurse when present
3. Log when recursion is triggered

### Phase 3: Enforce JSON (Future)

1. Make JSON format required
2. Reject non-JSON responses with retry
3. Remove fallback handling

---

## Success Criteria

- [ ] System prompt requests JSON format with hardened instructions
- [ ] `parse_llm_response()` handles valid JSON
- [ ] `parse_llm_response()` falls back gracefully on invalid JSON
- [ ] Confidence is clamped to [0.0, 1.0]
- [ ] Frame confidence comes from parsed JSON
- [ ] `sub_tasks` triggers automatic recursion
- [ ] `next_action` controls recursion (prevents infinite loops)
- [ ] `should_continue` and `should_ask_user` properties work
- [ ] Unit tests pass for parser (including edge cases)
- [ ] Integration test shows token savings
- [ ] Token savings logged for monitoring

---

## Token Savings Estimation

| Scenario | Before | After | Savings |
|----------|--------|-------|---------|
| Simple query | 200 tokens | 150 tokens | 25% |
| Complex analysis | 1000 tokens | 600 tokens | 40% |
| Multi-file review | 1500 tokens | 900 tokens | 40% |

**Expected average:** 30-40% reduction in LLM response tokens.

---

## Commit Message Template

```
feat: add structured JSON output for llm() calls

- Add JSON format enforcement to system prompt (hardened)
- Add safe JSON parser with fallback (json_parser.py)
- Add next_action field for recursion control
- Clamp confidence to [0.0, 1.0]
- Use parsed confidence for frame creation
- Handle sub_tasks field for explicit recursion
- Add should_continue / should_ask_user properties
- Log token savings for monitoring
- Unit tests for parser edge cases

Token savings: ~30-40% on complex responses
Reliability: No more fragile string parsing
Recursion control: next_action prevents infinite loops
```

---

## Suggested Timeline

| Day | Focus |
|-----|-------|
| Day 1 | Implement parser + prompt update + unit tests |
| Day 2 | Integrate into `llm_sync` + frame creation + sub_tasks recursion |
| Day 3 | Run 2-3 complex queries → measure token savings + debug parsing failures |

After this phase, the system will feel noticeably cheaper and more reliable — especially for multi-file analysis or deep recursion.
